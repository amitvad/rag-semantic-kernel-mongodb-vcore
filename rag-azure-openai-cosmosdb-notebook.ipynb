{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install the Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install semantic-kernel==1.17.1\n",
    "%pip install openai==1.58.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create your environment variables .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your environment variables then run the cell to create the *.env* file with your environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file if it doesn't exist\n",
    "%cp -n .env.example .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the environment variables file\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the parameters needed by [Azure Cosmos DB for MongoDB vCore](https://learn.microsoft.com/azure/cosmos-db/mongodb/vcore/vector-search) to create the vector search index are handled by semantic kernel.\n",
    "\n",
    "In this guide, we are using `text-embedding-ada-002` embedding model to generate the embeddings which uses a 1536-dimensional embedding vector.\n",
    "\n",
    "The `num_lists` is an integer that represents of clusters that the inverted file (IVF) index uses to group the vector data.\n",
    "\n",
    "The `similarity` used with IVF index here is the `COS` (cosine distance) but you can also try `L2` (Euclidean distance), and `IP` (inner product). For more information see the [Understand embeddings in Azure OpenAI Service article](https://learn.microsoft.com/azure/ai-services/openai/concepts/understand-embeddings#cosine-similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote_plus\n",
    "\n",
    "\n",
    "# Read and Store Environment variables\n",
    "def get_mongo_connection_string():\n",
    "    mongo_connection_string = os.getenv(\"AZURE_COSMOS_CONNECTION_STRING\", \"<YOUR-COSMOS-DB-CONNECTION-STRING>\")\n",
    "    mongo_username = quote_plus(os.getenv(\"AZURE_COSMOS_USERNAME\"))\n",
    "    mongo_password = quote_plus(os.getenv(\"AZURE_COSMOS_PASSWORD\"))\n",
    "    return mongo_connection_string.replace(\"<user>\", mongo_username).replace(\"<password>\", mongo_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cosmosdb.utils import (\n",
    "    CosmosDBSimilarityType,\n",
    "    CosmosDBVectorSearchType,\n",
    ")\n",
    "\n",
    "# collection name will be used multiple times in the code so we store it in a variable\n",
    "mongo_connection_string = get_mongo_connection_string()\n",
    "database_name = os.getenv(\"AZURE_COSMOS_DATABASE_NAME\")\n",
    "collection_name = os.getenv(\"AZURE_COSMOS_COLLECTION_NAME\")\n",
    "\n",
    "# Vector search index parameters\n",
    "index_name = os.getenv(\"AZURE_COSMOS_INDEX_NAME\", \"VectorSearchIndex\")\n",
    "vector_dimensions = 1536  # text-embedding-ada-002 uses a 1536-dimensional embedding vector\n",
    "num_lists = 100\n",
    "similarity = CosmosDBSimilarityType.COS\n",
    "kind = CosmosDBVectorSearchType.VECTOR_HNSW\n",
    "m = 16\n",
    "ef_construction = 64\n",
    "ef_search = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes in a json file of NoSQL records and checks if your data exists in the database using the id of the record then skips the record if it exists or generates embeddings and uploads the database record along with it's embedding.\n",
    "\n",
    "The `save_information` function does two things: generate embeddings + upload the data to your database.\n",
    "\n",
    "Learn more about the semantic kernel memory store [here](https://learn.microsoft.com/semantic-kernel/memories/) and the embeddings [here](https://learn.microsoft.com/semantic-kernel/memories/embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from semantic_kernel.memory.memory_store_base import MemoryStoreBase\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "\n",
    "\n",
    "async def upsert_data_to_memory_store(memory: SemanticTextMemory, store: MemoryStoreBase, data_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    This asynchronous function takes two memory stores and a data file path as arguments.\n",
    "    It is designed to upsert (update or insert) data into the memory stores from the data file.\n",
    "\n",
    "    Args:\n",
    "        memory (callable): A callable object that represents the semantic kernel memory.\n",
    "        store (callable): A callable object that represents the memory store where data will be upserted.\n",
    "        data_file_path (str): The path to the data file that contains the data to be upserted.\n",
    "\n",
    "    Returns:\n",
    "        None. The function performs an operation that modifies the memory stores in-place.\n",
    "    \"\"\"\n",
    "    with open(file=data_file_path, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        n = 0\n",
    "        for item in data:\n",
    "            n += 1\n",
    "            # check if the item already exists in the memory store\n",
    "            # if the id doesn't exist, it throws an exception\n",
    "            try:\n",
    "                already_created = bool(await store.get(collection_name, item[\"id\"], with_embedding=True))\n",
    "            except Exception:\n",
    "                already_created = False\n",
    "            # if the record doesn't exist, we generate embeddings and save it to the database\n",
    "            if not already_created:\n",
    "                await memory.save_information(\n",
    "                    collection=collection_name,\n",
    "                    id=item[\"id\"],\n",
    "                    # the embedding is generated from the text field\n",
    "                    text=item[\"content\"],\n",
    "                    description=item[\"title\"],\n",
    "                )\n",
    "                print(\n",
    "                    \"Generating embeddings and saving new item:\",\n",
    "                    n,\n",
    "                    \"/\",\n",
    "                    len(data),\n",
    "                    end=\"\\r\",\n",
    "                )\n",
    "            else:\n",
    "                print(\"Skipping item already exits:\", n, \"/\", len(data), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Add the Chat and Embedding models to the Semantic Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the semantic kernel, and initialize the semantic kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the needed libraries.\n",
    "\n",
    "We need the chat completion for having a conversation and text embeddings for generating embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the chat deployment name, initialize the chat completions with the required parameters, and add the created chat service to the semantic kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Azure OpenAI Chat Service...\n"
     ]
    }
   ],
   "source": [
    "# adding azure openai chat service\n",
    "chat_model_deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"chat_completion\",\n",
    "        deployment_name=chat_model_deployment_name,\n",
    "        endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "    )\n",
    ")\n",
    "print(\"Added Azure OpenAI Chat Service...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the embeddings deployment name and initialize the text embedding with the required parameters, and add the created embedding service to the semantic kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Azure OpenAI Embedding Generation Service...\n"
     ]
    }
   ],
   "source": [
    "# adding azure openai text embedding service\n",
    "embedding_model_deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\")\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureTextEmbedding(\n",
    "        service_id=\"text_embedding\",\n",
    "        deployment_name=embedding_model_deployment_name,\n",
    "        endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "    )\n",
    ")\n",
    "print(\"Added Azure OpenAI Embedding Generation Service...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create or Update Azure Cosmos DB for MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semantic kernel can handel the database, collection, index creation.\n",
    "\n",
    "Import the Azure CosmosDB memory store and initialize it with the parameters defined before.\n",
    "\n",
    "If the database, collection, and index exist it won't overwrite it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating or updating Azure Cosmos DB Memory Store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john0isaac/Developer/rag-semantic-kernel-mongodb-vcore/.venv/lib/python3.10/site-packages/semantic_kernel/connectors/memory/azure_cosmosdb/azure_cosmos_db_memory_store.py:102: UserWarning: You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb\n",
      "  mongodb_client = MongoClient(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished updating Azure Cosmos DB Memory Store...\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cosmosdb import (\n",
    "    AzureCosmosDBMemoryStore,\n",
    ")\n",
    "\n",
    "print(\"Creating or updating Azure Cosmos DB Memory Store...\")\n",
    "# create azure cosmos db for mongo db vcore api store and collection with vector ivf\n",
    "# currently, semantic kernel only supports the ivf vector kind\n",
    "store = await AzureCosmosDBMemoryStore.create(\n",
    "    cosmos_connstr=mongo_connection_string,\n",
    "    cosmos_api=\"mongo-vcore\",\n",
    "    database_name=database_name,\n",
    "    collection_name=collection_name,\n",
    "    index_name=index_name,\n",
    "    vector_dimensions=vector_dimensions,\n",
    "    num_lists=num_lists,\n",
    "    similarity=similarity,\n",
    "    kind=kind,\n",
    "    m=m,\n",
    "    ef_construction=ef_construction,\n",
    "    ef_search=ef_search,\n",
    ")\n",
    "print(\"Finished updating Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the created memory store to the semantic kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered Azure Cosmos DB Memory Store...\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "\n",
    "memory = SemanticTextMemory(storage=store, embeddings_generator=kernel.get_service(\"text_embedding\"))\n",
    "kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPluginACDB\")\n",
    "print(\"Registered Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generate embeddings and Create Database records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the helper function with the JSON data file to generate embeddings and create or update the database records.\n",
    "\n",
    "If the records already exit it will skip it.\n",
    "\n",
    "Records are identified by their ids.\n",
    "\n",
    "The data used here is a dummy data which you can replace with your own.\n",
    "\n",
    "**Note that you need to specify id, text, and description fields.\n",
    "The text field is what gets converted to embeddings.**\n",
    "\n",
    "See the helper function definition for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting data to Azure Cosmos DB Memory Store...\n",
      "Generating embeddings and saving new item: 344 / 344\r"
     ]
    }
   ],
   "source": [
    "# cleaned-top-movies-chunked.json contains the top 344 movie from the IMDB movies dataset\n",
    "# You can also try the text-sample.json which contains 107 Azure Service.\n",
    "# Replace the file name cleaned-top-movies-chunked.json with text-sample.json\n",
    "\n",
    "print(\"Upserting data to Azure Cosmos DB Memory Store...\")\n",
    "await upsert_data_to_memory_store(memory, store, \"./src/data/cleaned-top-movies-chunked.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Test the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search function converts the query_term to a vector embedding and finds the similarity between it and the database records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each time it calls the embedding model to generate embeddings from your query\n",
    "query_term = \"What do you know about the godfather?\"\n",
    "result = await memory.search(collection_name, query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is: The Godfather: The aging patriarch of an organized crime dynasty transfers control of his clandestine empire to his reluctant son.\n",
      "Relevance Score: 0.875689260702724\n",
      "Full Record: {\"text\": \"The Godfather: The aging patriarch of an organized crime dynasty transfers control of his clandestine empire to his reluctant son.\", \"description\": \"The Godfather\", \"additional_metadata\": null}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Result is: {result[0].text}\\nRelevance Score: {result[0].relevance}\\nFull Record: {result[0].additional_metadata}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Create chat function with Azure OpenAI chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a chatbot that can have a conversations about any topic related to the provided context.\n",
    "    Give explicit answers from the provided context or say 'I don't know' if it does not have an answer.\n",
    "    provided context: {{$db_record}}\n",
    "\n",
    "    User: {{$query_term}}\n",
    "    Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextPromptExecutionSettings\n",
    "\n",
    "execution_settings = OpenAITextPromptExecutionSettings(\n",
    "    service_id=\"chat_completion\", ai_model_id=chat_model_deployment_name, max_tokens=500, temperature=0.0, top_p=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "\n",
    "chat_prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"grounded_response\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"db_record\", description=\"The database record\", is_required=True),\n",
    "        InputVariable(name=\"query_term\", description=\"The user input\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=execution_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function = kernel.add_function(\n",
    "    function_name=\"ChatGPTFunc\", plugin_name=\"chatGPTPlugin\", prompt_template_config=chat_prompt_template_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "completions_result = await kernel.invoke(\n",
    "    chat_function, KernelArguments(query_term=query_term, db_record=result[0].additional_metadata)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Godfather is a movie about the aging patriarch of an organized crime dynasty who transfers control of his clandestine empire to his reluctant son.\n"
     ]
    }
   ],
   "source": [
    "print(completions_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Testing the RAG flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Hey\n",
      "Response:\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "Question:\n",
      "Do you know any crime dynasty movies?\n",
      "Response:\n",
      "Yes, \"The Godfather\" is a crime dynasty movie.\n",
      "\n",
      "Question:\n",
      "can you recommend me movies like the god father?\n",
      "Response:\n",
      "Sure! If you enjoyed \"The Godfather,\" you might also like these movies:\n",
      "1. \"Goodfellas\" (1990) - A story about the rise and fall of a mob associate in the Italian-American crime syndicate.\n",
      "2. \"Scarface\" (1983) - A tale of a Cuban immigrant who becomes a powerful drug lord in Miami.\n",
      "3. \"The Departed\" (2006) - A gripping crime thriller about an undercover cop and a mole in the police force.\n",
      "4. \"Casino\" (1995) - A film that explores the inner workings of a Las Vegas casino and the mob's influence on it.\n",
      "5. \"Once Upon a Time in America\" (1984) - A saga spanning several decades, following a group of Jewish gangsters in New York City.\n",
      "\n",
      "These movies share similar themes of organized crime, family dynamics, and the complex world of the mafia. Enjoy!\n",
      "\n",
      "Question:\n",
      "thanks, bye!\n",
      "Response:\n",
      "You're welcome! Goodbye!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query_term = \"\"\n",
    "search_result = \"\"\n",
    "completions_result = \"\"\n",
    "\n",
    "while query_term != \"exit\":\n",
    "    query_term = input(\"Enter a query: \")\n",
    "    if query_term == \"exit\":\n",
    "        break\n",
    "    search_result = await memory.search(collection_name, query_term)\n",
    "    completions_result = kernel.invoke_stream(\n",
    "        chat_function, KernelArguments(query_term=query_term, db_record=search_result[0].additional_metadata)\n",
    "    )\n",
    "    print(f\"Question:\\n{query_term}\\nResponse:\")\n",
    "    async for completion in completions_result:\n",
    "        print(str(completion[0]), end=\"\")\n",
    "    print(\"\\n\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[Optional]** Adding Chat History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chat history is local (i.e. in your computer's RAM) and not persisted anywhere beyond the life of this Jupyter session.\n",
    "In this chat scenario, as the user talks back and forth with the bot, the chat context gets populated with the history of the conversation. During each new run of the kernel, the kernel arguments and chat history can provide the AI with its variables' content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_prompt = \"\"\"\n",
    "    You are a chatbot that can have a conversations about any topic related to the provided context.\n",
    "    Give explicit answers from the provided context or say 'I don't know' if it does not have an answer.\n",
    "    provided context: {{$db_record}}\n",
    "\n",
    "    {{$history}}\n",
    "    \n",
    "    User: {{$query_term}}\n",
    "    Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_hist_template_config = PromptTemplateConfig(\n",
    "    template=history_prompt,\n",
    "    name=\"grounded_response_history\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"db_record\", description=\"The database record\", is_required=True),\n",
    "        InputVariable(name=\"query_term\", description=\"The user input\", is_required=True),\n",
    "        InputVariable(name=\"history\", description=\"The chat histroy\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=execution_settings,\n",
    ")\n",
    "\n",
    "chat_history_function = kernel.add_function(\n",
    "    function_name=\"ChatGPTFuncHist\",\n",
    "    plugin_name=\"chatGPTPluginHist\",\n",
    "    prompt_template_config=chat_prompt_hist_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_system_message(\"You are a helpful chatbot who is good about giving movie recommendations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Hey\n",
      "Response:\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "Question:\n",
      "Do you know any comedy movies?\n",
      "Response:\n",
      "Yes, I can recommend some comedy movies for you. Here are a few popular ones:\n",
      "\n",
      "1. \"Anchorman: The Legend of Ron Burgundy\" - A hilarious comedy about a 1970s news anchor and his eccentric news team.\n",
      "2. \"Superbad\" - A coming-of-age comedy about two high school friends who embark on a wild night of partying before graduation.\n",
      "3. \"Bridesmaids\" - A comedy about the lead-up to a wedding, filled with hilarious mishaps and memorable characters.\n",
      "4. \"The Hangover\" - A comedy about a group of friends who wake up after a wild bachelor party in Las Vegas, trying to piece together what happened.\n",
      "5. \"Step Brothers\" - A comedy about two middle-aged men who become stepbrothers and wreak havoc on their parents' lives.\n",
      "\n",
      "I hope you find these recommendations enjoyable! Let me know if you need more suggestions.\n",
      "\n",
      "Question:\n",
      "can you tell me more about the first movie?\n",
      "Response:\n",
      "Certainly! \"Anchorman: The Legend of Ron Burgundy\" is a comedy film released in 2004. It is set in the 1970s and follows the story of Ron Burgundy, a charismatic and egotistical news anchor in San Diego. Ron is the top-rated newsman in the city, but his world is turned upside down when a talented and ambitious female reporter named Veronica Corningstone joins the news team.\n",
      "\n",
      "The movie showcases Ron's hilarious attempts to maintain his dominance in the news industry while dealing with the challenges of working alongside Veronica. It features a talented ensemble cast including Will Ferrell as Ron Burgundy, Christina Applegate as Veronica Corningstone, and Steve Carell, Paul Rudd, and David Koechner as Ron's eccentric news team.\n",
      "\n",
      "\"Anchorman: The Legend of Ron Burgundy\" is known for its absurd humor, quotable lines, and memorable characters. It has become a cult classic and is beloved by fans of comedy films. If you enjoy witty and offbeat humor, this movie is definitely worth a watch!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query_term = \"\"\n",
    "search_result = \"\"\n",
    "completions_result = \"\"\n",
    "\n",
    "while query_term != \"exit\":\n",
    "    query_term = input(\"Enter a query: \")\n",
    "    if query_term == \"exit\":\n",
    "        break\n",
    "    chat_history.add_user_message(query_term)\n",
    "\n",
    "    search_result = await memory.search(collection_name, query_term)  # vector search\n",
    "\n",
    "    completions_result = await kernel.invoke(\n",
    "        chat_history_function,\n",
    "        KernelArguments(query_term=query_term, db_record=search_result[0].additional_metadata, history=chat_history),\n",
    "    )  # RAG\n",
    "    chat_history.add_assistant_message(str(completions_result))\n",
    "\n",
    "    print(f\"Question:\\n{query_term}\\nResponse:\")\n",
    "    print(str(completions_result), end=\"\")\n",
    "    print(\"\\n\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After chatting for a while, we have built a growing history, which we are attaching to each prompt and which contains the full conversation. Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chat_history><message role=\"system\"><text>You are a helpful chatbot who is good about giving movie recommendations.</text></message><message role=\"user\"><text>Hey</text></message><message role=\"assistant\"><text>Hello! How can I assist you today?</text></message><message role=\"user\"><text>Do you know any comedy movies?</text></message><message role=\"assistant\"><text>Yes, I can recommend some comedy movies for you. Here are a few popular ones:\n",
      "\n",
      "1. \"Anchorman: The Legend of Ron Burgundy\" - A hilarious comedy about a 1970s news anchor and his eccentric news team.\n",
      "2. \"Superbad\" - A coming-of-age comedy about two high school friends who embark on a wild night of partying before graduation.\n",
      "3. \"Bridesmaids\" - A comedy about the lead-up to a wedding, filled with hilarious mishaps and memorable characters.\n",
      "4. \"The Hangover\" - A comedy about a group of friends who wake up after a wild bachelor party in Las Vegas, trying to piece together what happened.\n",
      "5. \"Step Brothers\" - A comedy about two middle-aged men who become stepbrothers and wreak havoc on their parents' lives.\n",
      "\n",
      "I hope you find these recommendations enjoyable! Let me know if you need more suggestions.</text></message><message role=\"user\"><text>can you tell me more about the first movie?</text></message><message role=\"assistant\"><text>Certainly! \"Anchorman: The Legend of Ron Burgundy\" is a comedy film released in 2004. It is set in the 1970s and follows the story of Ron Burgundy, a charismatic and egotistical news anchor in San Diego. Ron is the top-rated newsman in the city, but his world is turned upside down when a talented and ambitious female reporter named Veronica Corningstone joins the news team.\n",
      "\n",
      "The movie showcases Ron's hilarious attempts to maintain his dominance in the news industry while dealing with the challenges of working alongside Veronica. It features a talented ensemble cast including Will Ferrell as Ron Burgundy, Christina Applegate as Veronica Corningstone, and Steve Carell, Paul Rudd, and David Koechner as Ron's eccentric news team.\n",
      "\n",
      "\"Anchorman: The Legend of Ron Burgundy\" is known for its absurd humor, quotable lines, and memorable characters. It has become a cult classic and is beloved by fans of comedy films. If you enjoy witty and offbeat humor, this movie is definitely worth a watch!</text></message></chat_history>\n"
     ]
    }
   ],
   "source": [
    "print(chat_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
